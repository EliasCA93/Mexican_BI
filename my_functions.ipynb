{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27b95104",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Don't repeat yourself (dry)\n",
    "\n",
    "> Elias Castellanos Alamilla\n",
    "\n",
    "> April-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "477c6bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pylab import rcParams\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib import cm\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "from sklearn.metrics import silhouette_samples\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "import scipy.cluster.hierarchy as sch\n",
    "\n",
    "from io import StringIO\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be8bf9f",
   "metadata": {},
   "source": [
    "## Data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cdb8901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_sql_data(db_connection: dict, df: pd.DataFrame, name: str):\n",
    "    \"\"\"\n",
    "    Save data gathering into mySQL database.\n",
    "    Args: \n",
    "        - db_connection: database connection credentials. (host, user, password, database)\n",
    "        - df: pandas DataFrame.\n",
    "        - name: new table name.\n",
    "    Returns:\n",
    "        - None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        engine = create_engine(f\"mysql+pymysql://{db_connection['user']}:{db_connection['password']}@{db_connection['host']}/{db_connection['db']}\")\n",
    "\n",
    "        df.to_sql(name, engine, if_exists='fail')\n",
    "\n",
    "        print(\"Data send succesfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error sending data to SQL: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6af83208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the compare_and_aggregate function\n",
    "def compare_and_aggregate(local_data, db_data_query, db_connection, table_name):\n",
    "    \"\"\"\n",
    "    Compares local data with database data and aggregates new data to a MySQL table.\n",
    "\n",
    "    Args:\n",
    "        local_data (pandas DataFrame): Local data to compare.\n",
    "        db_data_query (str): SQL query to retrieve database data.\n",
    "        db_connection (dict): Dictionary containing MySQL database connection details.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Check if local_data is a Pandas DataFrame\n",
    "    if not isinstance(local_data, pd.DataFrame):\n",
    "        raise ValueError(\"local_data must be a Pandas DataFrame\")\n",
    "        \n",
    "    # Check if local_data has at least one row\n",
    "    if local_data.empty:\n",
    "        print(\"local_data is empty, no comparison or aggregation, check your data.\")\n",
    "        return None\n",
    "    \n",
    "    # Replace 'NaT' values with None\n",
    "    local_data = local_data.fillna(method='ffill')\n",
    "    \n",
    "    \n",
    "    # Connect to MySQL database\n",
    "    conn = pymysql.connect(\n",
    "        host=db_connection['host'],\n",
    "        user=db_connection['user'],\n",
    "        password=db_connection['password'],\n",
    "        db=db_connection['db'],\n",
    "        cursorclass=pymysql.cursors.DictCursor\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Retrieve data from MySQL table\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(db_data_query)\n",
    "            result = cursor.fetchall()\n",
    "\n",
    "        # Convert MySQL data to DataFrame\n",
    "        db_df = pd.DataFrame(result)\n",
    "        \n",
    "        # Check if local_data has the same number of columns as db_df\n",
    "        if local_data.shape[1] != db_df.shape[1]:\n",
    "            raise ValueError(\"local_data has a different number of columns compared to database data\")\n",
    "\n",
    "        # Compare local data with database data\n",
    "        common_cols = list(set(local_data.columns) & set(db_df.columns))\n",
    "        new_data = local_data[~local_data[common_cols].isin(db_df[common_cols].values.ravel()).all(axis=1)]\n",
    "\n",
    "        # Aggregate new data to MySQL table\n",
    "        if not new_data.empty:\n",
    "            with conn.cursor() as cursor:\n",
    "                for _, row in new_data.iterrows():\n",
    "                    row['MME'] = round(row['MME'], 2)\n",
    "                    cols = ', '.join(new_data.columns)\n",
    "                    vals = ', '.join(['%s'] * len(new_data.columns))\n",
    "                    query = f\"INSERT INTO {table_name} ({cols}) VALUES ({vals})\"\n",
    "                    cursor.execute(query, tuple(row))\n",
    "                conn.commit()\n",
    "            print(f\"{len(new_data)} rows of new data added to MySQL table.\")\n",
    "        else:\n",
    "            print(\"No new data to add to MySQL table.\")\n",
    "    finally:\n",
    "        # Close database connection\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c1bb329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sql_data(db_connection: dict, tablename: str):\n",
    "    \"\"\"\n",
    "    Load data from mySQL database.\n",
    "    Args: \n",
    "        - db_connection: database connection credentials. (host, user, password, database)\n",
    "        - tablename: table name to query.\n",
    "    Returns:\n",
    "        - pandas DataFrame.\n",
    "    \"\"\"\n",
    "    engine = create_engine(f\"mysql+pymysql://{db_connection['user']}:{db_connection['password']}@{db_connection['host']}/{db_connection['db']}\")\n",
    "    query = f'SELECT * FROM {tablename}'\n",
    "    df = pd.read_sql_query(text(query), con=engine.connect())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73927144",
   "metadata": {},
   "source": [
    "## Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "945b8617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_bmx_timeseries(token, series, start_date: str):\n",
    "    \"\"\"\n",
    "    Web Scraping function to get time series data from Banxico repository.\n",
    "    :param serie: IDSerie, ej. SF63528 (str). https://www.banxico.org.mx/SieAPIRest/service/v1/\n",
    "    :param start_date: date format yyyy-mm-dd.\n",
    "    :param end_date: date format yyyy-mm-dd.\n",
    "    :param token: API token Banxico, length 64 characteres. https://www.banxico.org.mx/SieAPIRest/service/v1/token\n",
    "    :return: Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    end_date = pd.to_datetime('today', format='%Y-%m-%d')\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='MS')\n",
    "    url = 'https://www.banxico.org.mx/SieAPIRest/service/v1/series/'+series+'/datos/'+start_date+'/'+str(date_range[-1].date())+''\n",
    "    print(url)\n",
    "    headers = {'Bmx-Token':token}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    status = response.status_code\n",
    "    if status != 200:\n",
    "        return print(\"Error, status code: {}\".format(status))\n",
    "    raw_data = response.json()\n",
    "    data = raw_data['bmx']['series'][0]['datos']\n",
    "    df = pd.DataFrame(data)\n",
    "    df.replace(to_replace='N/E', value='NaN', inplace=True)\n",
    "    df['dato'] = df['dato'].apply(lambda x:float(x))\n",
    "    df['fecha'] = pd.to_datetime(df['fecha'], format='%d/%m/%Y')\n",
    "    df.set_index('fecha', inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4853fa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mme_prices():\n",
    "    \"\"\"\n",
    "    Only web scrape oil & gas mx prices, no token require.\n",
    "    Args:\n",
    "        - No args.\n",
    "    Return: \n",
    "        - pandas DataFrame.\n",
    "    \"\"\"\n",
    "    # Precios MME Banxico\n",
    "    url = \"https://www.banxico.org.mx/SieInternet/consultaSerieGrafica.do?s=SI744,CI38\"\n",
    "    f = urllib.request.urlopen(url)\n",
    "    myfile = f.read()\n",
    "\n",
    "    # Get string data format\n",
    "    string_data = str(myfile, 'utf-8')\n",
    "\n",
    "    # Convert string to json format\n",
    "    json_data = json.loads(string_data)\n",
    "\n",
    "    # Tabular data\n",
    "    df = pd.DataFrame(json_data['valores'], columns=['fecha', 'MME'])\n",
    "\n",
    "    # replace values \"-989898.00\" related with NaN values \n",
    "    array = np.where(np.isclose(df['MME'].values, -989898.00), np.nan, df['MME'].values)\n",
    "\n",
    "    # Transform to pandas DataFrame\n",
    "    mme_clean = pd.DataFrame(array, columns=['MME'])\n",
    "    mme_clean\n",
    "\n",
    "    # Insert NaN values\n",
    "    df['MME'] = mme_clean\n",
    "\n",
    "    # Set datetimeindex\n",
    "    df['fecha'] = pd.to_datetime(df['fecha'], format='%Y-%m-%d')\n",
    "    df.set_index('fecha', inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c8fbf4",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/53426787/how-to-replace-a-float-value-with-nan-in-pandas\n",
    "https://stackoverflow.com/questions/15138614/how-can-i-read-the-contents-of-an-url-with-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bed3cca",
   "metadata": {},
   "source": [
    "# Data Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25912e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_cells(val):\n",
    "    \"\"\"\n",
    "    Conditonal formatting based on correlation values.\n",
    "    Args:\n",
    "        - val: values to compare.\n",
    "    Returns:\n",
    "        - format color\n",
    "    \"\"\"\n",
    "    color = 'yellow' if (val >= 0.6 or val <= -0.6) else '#C6E2E9' # Pastel blue\n",
    "    \n",
    "    return 'background-color: {}'.format(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "393ffe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib colors table \n",
    "# https://matplotlib.org/stable/gallery/color/named_colors.html\n",
    "\n",
    "def plot_colortable(colors, sort_colors=True, emptycols=0):\n",
    "    \"\"\"\n",
    "    Function to visualize the available colors in matplotlib.\n",
    "    :param colors: CSS matplotlib colors (matplotlib.colors.CSS4_COLORS)\n",
    "    :return: Matplotlib figure with available colors based on CSS.\n",
    "    \"\"\"\n",
    "\n",
    "    cell_width = 212\n",
    "    cell_height = 22\n",
    "    swatch_width = 48\n",
    "    margin = 12\n",
    "\n",
    "    # Sort colors by hue, saturation, value and name.\n",
    "    if sort_colors is True:\n",
    "        by_hsv = sorted((tuple(mcolors.rgb_to_hsv(mcolors.to_rgb(color))),\n",
    "                         name)\n",
    "                        for name, color in colors.items())\n",
    "        names = [name for hsv, name in by_hsv]\n",
    "    else:\n",
    "        names = list(colors)\n",
    "\n",
    "    n = len(names)\n",
    "    ncols = 4 - emptycols\n",
    "    nrows = n // ncols + int(n % ncols > 0)\n",
    "\n",
    "    width = cell_width * 4 + 2 * margin\n",
    "    height = cell_height * nrows + 2 * margin\n",
    "    dpi = 72\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(width / dpi, height / dpi), dpi=dpi)\n",
    "    fig.subplots_adjust(margin/width, margin/height,\n",
    "                        (width-margin)/width, (height-margin)/height)\n",
    "    ax.set_xlim(0, cell_width * 4)\n",
    "    ax.set_ylim(cell_height * (nrows-0.5), -cell_height/2.)\n",
    "    ax.yaxis.set_visible(False)\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    for i, name in enumerate(names):\n",
    "        row = i % nrows\n",
    "        col = i // nrows\n",
    "        y = row * cell_height\n",
    "\n",
    "        swatch_start_x = cell_width * col\n",
    "        text_pos_x = cell_width * col + swatch_width + 7\n",
    "\n",
    "        ax.text(text_pos_x, y, name, fontsize=14,\n",
    "                horizontalalignment='left',\n",
    "                verticalalignment='center')\n",
    "\n",
    "        ax.add_patch(\n",
    "            Rectangle(xy=(swatch_start_x, y-9), width=swatch_width,\n",
    "                      height=18, facecolor=colors[name], edgecolor='0.7')\n",
    "        )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c7a957b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation(color, title, df={}):\n",
    "    \"\"\"\n",
    "    Function to plot pearson correlation gradients between variables.\n",
    "    :param color: cmap heatmap option. i.e. \"Blues\", \"coolwarm\", \"jet\", etc.\n",
    "    :param df: Pandas DataFrame.\n",
    "    :returns: matplotlib figure.\n",
    "    \"\"\"\n",
    "    # calculate pearson correlation\n",
    "    corr = df.corr()\n",
    "    \n",
    "    # mask for mask heatmap parameter\n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "    \n",
    "    # create figure\n",
    "    fig = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    # create plot\n",
    "    sns.heatmap(corr, mask=mask, annot=True, cmap=color, linewidths=1, center=0)\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b456c787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seasonal_decomposition(df, select_period, model='additive'):\n",
    "    \"\"\"\n",
    "    Decompose a timeseries dataset into trend, seasonal, residuals, and plot it.\n",
    "    :param df: Timeseries data in Pandas DataFrame format. It's optional.\n",
    "    :param model: seasonal decompose model, i.e., additive\n",
    "    :param period: period for seasonal decompose, i.e., 12 means monthly seasonal, 3 means quarter\n",
    "    :return: plot figure seasonal decompose (matplotlib figure).\n",
    "    \"\"\"\n",
    "    \n",
    "    matplotlib.rcParams['axes.labelsize'] = 14\n",
    "    matplotlib.rcParams['xtick.labelsize'] = 12\n",
    "    matplotlib.rcParams['ytick.labelsize'] = 12\n",
    "    matplotlib.rcParams['text.color'] = 'k'\n",
    "    \n",
    "    rcParams['figure.figsize'] = 18, 8\n",
    "    decomposition = seasonal_decompose(x=df, model=model, period=select_period)\n",
    "    fig = decomposition.plot()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ed546e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_data_preprocessing(df={}):\n",
    "    \"\"\"Data preprocessing for PCA, Standard Scaler.\n",
    "    \n",
    "    Args:\n",
    "        df(DataFrame): Numeric information in original scale.\n",
    "        new_object(Standard_df): Pandas DataFrame with data preprocessing by Standard Scaler\n",
    "        \n",
    "    Returns:\n",
    "        Pandas DataFrame with preprocessing values\n",
    "    \"\"\"\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(df)\n",
    "    data_std = ss.transform(df)\n",
    "    \n",
    "    df_std = pd.DataFrame(data_std, columns=df.columns)\n",
    "    \n",
    "    return df_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc35a3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_pipeline_viz(df, xlabel: str, ylabel: str, title: str):\n",
    "    \"\"\"\n",
    "    Plot PCA elbow method. \n",
    "    Visual tool that helps to choose the number of principal components for PCA.\n",
    "    :param df: Pandas DataFrame\n",
    "    :param xlabel: X label legend for plot xaxis.\n",
    "    :param ylabel: Y label legend for plot yaxis.\n",
    "    :param title: Legend for plot title.\n",
    "    :return: Matplotlib figure to visualize PCA elbow method.\n",
    "    \"\"\"\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()), \n",
    "        ('dr', PCA())\n",
    "    ])\n",
    "    \n",
    "    pipe.fit(df)\n",
    "    \n",
    "    var = pipe.steps[1][1].explained_variance_ratio_.cumsum()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    plt.plot(var, marker='o')\n",
    "    \n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "    \n",
    "    return var, fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34f1f2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dendrogram(df, xlabel: str, ylabel: str, title: str, y_top: float, y_base: float):\n",
    "    \"\"\"Hieriarchical clustering dendrogram figure.\n",
    "    Visual tool that helps to choose the number of cluster for an unsupervised model.\n",
    "    :param df: Pandas DataFrame\n",
    "    :param xlabel: X label legend for plot xaxis.\n",
    "    :param ylabel: Y label legend for plot yaxis.\n",
    "    :param title: Legend for plot title.\n",
    "    :return: Matplotlib figure to visualize Dendrogram method for clustering models.\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "    dend = sch.dendrogram(sch.linkage(df, method='ward'))\n",
    "    \n",
    "    ax.axhline(y=y_top, c='grey', lw=1, linestyle='dashed')\n",
    "    ax.axhline(y=y_base, c='grey', lw=1, linestyle='dashed')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xticks([])\n",
    "    plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cd42879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_silhoutte_coeff(array, df, xlabel: str, ylabel: str, title: str): \n",
    "    \"\"\"Silhouette coefficient helps to check the quality of our predicted clusters.\n",
    "    Y_label = Cluster.\n",
    "    X_label = Silhouette coefficient.\n",
    "    Title = Silhouette coefficient plot.\n",
    "    :param df: Pandas DataFrame\n",
    "    :param xlabel: X label legend for plot xaxis.\n",
    "    :param ylabel: Y label legend for plot yaxis.\n",
    "    :param title: Legend for plot title.\n",
    "    :return: Matplotlib figure to visualize Silhouette coefficient to measure the quality of clustering results\n",
    "    \"\"\"\n",
    "    cluster_labels = np.unique(array)\n",
    "    n_clusters = cluster_labels.shape[0]\n",
    "    silhouette_vals = silhouette_samples(df, array, metric='euclidean')\n",
    "    y_ax_lower, y_ax_upper = 0,0\n",
    "    yticks = []\n",
    "    fig = plt.subplots(figsize=(15,10))\n",
    "    for i, c in enumerate (cluster_labels):\n",
    "        c_silhouette_vals  = silhouette_vals[array==c]\n",
    "        c_silhouette_vals.sort()\n",
    "        y_ax_upper += len(c_silhouette_vals)\n",
    "        color = cm.jet(float(i)/n_clusters)\n",
    "        plt.barh(range(y_ax_lower, y_ax_upper), c_silhouette_vals,height=1, edgecolor='none', color=color)\n",
    "        yticks.append((y_ax_lower + y_ax_upper)/2.)\n",
    "        y_ax_lower += len(c_silhouette_vals)\n",
    "    silhouette_avg = np.mean(silhouette_vals)\n",
    "    plt.axvline(silhouette_avg, color='red', linestyle=\"--\")\n",
    "    plt.yticks(yticks, cluster_labels + 1)\n",
    "\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.title(title)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd310bea",
   "metadata": {},
   "source": [
    "# Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "816cc60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, feature: str, year_train: str, year_test: str):\n",
    "    \"\"\"\n",
    "    Split data into train and test set for SARIMAX model, make sure to set_index in DatetimeIndex format.\n",
    "    :param df: pandas DataFrame.\n",
    "    :param feature: Feature to split. \n",
    "    :param year_train: Year for training data, i.e. '2014'\n",
    "    :param year_test: Year for testing data, i.e. '2015'\n",
    "    :returns: Split train and test DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    train = df[[feature]].loc[:year_train]\n",
    "    test = df[[feature]].loc[year_test:]\n",
    "    \n",
    "    return train, test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
